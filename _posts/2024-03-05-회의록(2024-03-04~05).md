# 2024/03/04~05(월,화)

회의장소: 디스코드

⌚회의 시간 : 2024.03.04 23:45~2024.03.05 01:00 ( 총 1시간 15분 소요)

👤참석자 : 전준표, 조민수, 이민석, 유재휘

🌐회의 장소 :  디스코드

📝작성자 :  조민수

(로테이션 : 이민석 → 전준표 → 조민수 → 유재휘)

## 🔳 **회의 주제 및 목적**

- 피드백 방안에 대한 해결방안 제시

## 🔳 **회의 내용**

1. 피드백 저작권에 대한 정보 : 해당 이미지가 게재된 논문을 찾아본 결과 © Copyright 2020 Korea Computer Graphics Society. This is an Open-Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License ([http://creativecommons.org/licenses/by-nc/4.0/](http://creativecommons.org/licenses/by-nc/4.0/)) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. 
    
    → 출처 표시 및 비영리 이용 목적이라면 자유롭게 사용 가능 
    
    - 교수님의 피드백 중 저작권에 대한 문제 x
2. 문제점 : 외국인들이 한국어를 배울 때 어려워 하는 점이 단어를 발음할 때 써 있는 그대로 읽으면 안된다는 점.
    - ex). 시점 [시쩜] - 경음화 , 한국말[한궁말] - 비음화
    - 하지만 기존 서비스는 이러한 음운의 변동규칙을 평가하기에는 부적합함. → 정확한 음성 인식 결과만을 추구하여 텍스트값을 뽑아주는 것이 STT의 평가기준이 되기 때문에
        - 예시) 한국어 음성인식 API에서 가장 높은 정확도를 보여준 모델 두 개(리턴제로, Naver clover speech)를 대상으로 실험.
            - “사건”이라는 단어는 쓸 때는 “사건”이지만 읽을 때는 [사껀]이라 읽음. 하지만 사용자가 발음을 [사건] 으로 해도 [사껀]으로 해도 모두 “사건”이라는 결과값만 보여주었음
            
        - 음성 전사 : 발성된 내용을 소리 값에 최대한 가깝게 표기
        - 철자 전사 : 철자법에 맞추어 표기
        
3. 제안
    - 기존의 STT에서 사용자의 발음을 들리는 그대로 정확하게 받아올 수 있도록 모델 훈련 or 데이터 전/후처리

1. 기존 한국어 음성 데이터셋의 경우 철자 전사를 토대로 label이 구축되어 있음 → label에 한해서 새로 데이터 구축

## 🔳 **회의 결과**

03.03 10:00 조교 피드백을 진행 후 해결 방법 구체화 및 신청서 재작성

## ✔️할 일