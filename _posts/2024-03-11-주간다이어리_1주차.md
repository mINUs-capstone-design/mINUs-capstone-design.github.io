---
layout: single
title:  "weekly diary - week 1"
excerpt: "..."
categories: weeklyDiary

toc: true
toc_sticky: true
---

# 주간 다이어리 1주차 (3월 4일 ~ 3월 10일)

## 활동 기록

---

팀 활동

- 3월 4일(월) 10:00 ~ 10:40
- 3월 4일(월) ~ 3월 5일(화) 23:45 ~ 25:00
- 3월 5일(화) 10:00 ~ 10:20
- 3월 7일(목) 16:50 ~ 20:20
- 3월 8일(금) 21:30 ~ 24:00
- 3월 10일(일) 12:00 ~ 22:00

**→  총 19시간 15분 진행**

개별 활동

- 새로운 주제 및 개선안 조사에 관한 시간은 미 기입.

## 진행 상황

---

### 1) 주제 신청 및 반려 사유 분석

첫 번째 주제 신청 반려 후, 피드백을 받아 다음과 같은 기능을 추가하여 2차 주제 신청.

- 데이터셋을 음운 변동규칙을 적용하여 (발음대로) 재 labeling. 이를 통한 발음의 정확도를 향상
- 기존 반려사유에 포함되어 있던 3D 피드백 영상의 저작권 문제 해결
  - → 2번 째 신청 반려

주제 반려 사유를 통해 현재 팀 주제의 문제점을 분석

- [mINUs] - 반려 / 주제 변경 또는 축약 필요
  데이터셋을 다시 레이블링한다면, 데이터셋 준비기간만 한 달 이상 걸릴 것으로 우려됨.
  만약 데이터셋을 다시 준비한다고 했을 때, error rate가 높다면 다시 데이터셋을 더 준비할 것인지에 대한 설명이 필요함.
  또한 이미지가 아닌 음성 pcm 데이터뭉치로 레이블링할 것인데 이미지에 비해 준비기간이 더 걸릴 수 있다는 의문이 들음.
  해당 제품의 핵심 기술은 음성 인식인데, 해당 부분은 기존 아이디어를 그대로 승계하는 방식이라 적합하지 않다고 보임.

**→ 데이터셋 준비 기간이 너무 길고 제대로 될 지 불확실**

**→ 핵심 기술인 음성인식이 기존 방법을 그대로 사용하기에 주제로서 부적합**.

### 2) 새로운 주제 선정

기존 주제의 돌파구를 찾으면서 동시에 새로운 주제의 후보를 선정하였다.

- 조도 센서를 이용한 화장대 LED 밝기 자동 조정

  - 자동으로 LED를 조정하는 것에 대한 필요성 의문

- 음성인식 도어락

  - 사람마다 목소리 구별 가능 기술 확인 필요
    - 화자 종속 음성 인식 기술 사용
  - AI 목소리와 실제 사람의 목소리 구별 기술 확인 필요

- 가상 면접 AI

  - 유사 제품 존재

    [뷰인터HRㅣ솔루션ㅣ솔루션 소개 - 뷰인터HR](https://viewinterhr.com/solution/?utm_source=Google_sa&utm_medium=cpc&utm_campaign=mo&utm_content=면접&utm_term=면접&utm_term=면접&utm_campaign=검색광고_MO&utm_source=adwords&utm_medium=ppc&hsa_acc=7386439546&hsa_cam=21053359086&hsa_grp=162453614794&hsa_ad=692238998393&hsa_src=g&hsa_tgt=kwd-5316166314&hsa_kw=면접&hsa_mt=b&hsa_net=adwords&hsa_ver=3&gad_source=1&gclid=CjwKCAiA6KWvBhAREiwAFPZM7mMuKwIB0L0DV4kQU6RJBSD_sAtSQ4HGmv8_-yiiWjIAmFyzg_ugKRoCr4sQAvD_BwE)

→ 오프라인 회의에서 다같이 새로운 아이디어를 생각했지만 가치가 있어보이는 아이디어가 마땅히 떠오르는 것이 없었기 때문에 기존의 아이디어에서 새로운 해결방안을 찾아보는 방향으로 전환하였다.

### 3) 기존 주제의 새로운 해결방안 제시 및 계획서 수정

데이터 셋의 전처리 문제를 해결하면서 기존의 음성인식(STT)를 사용하지 않고 발음을 분석할 수 있는 방안이 있을지에 대해 생각하였다. 이를 위해 음성 데이터에 대한 스터디를 진행하면서 해결책을 조사하였다.

- 소리의 크기 : 파형의 amplitude에 관계

- 소리의 높낮이 : 파형의 frequency에 관계

- 가청 주파수의 범위 : 20~20000Hz

- 음성 데이터는 파형그래프와 주파수 그래프로 표현 가능

  - 파형그래프

    - 소리 센서로 측정한 값. 가로 축 시간, 세로 축 진폭(음의 크기)

  - 주파수 그래프

    - 파형을 주파수에 따른 크기로 변형하여 나타내는 그래프

      - 스펙트로그램(spectrogram : 소리나 파동을 시각화하여 파악하기 위한 도구. 파형과 스펙트럼의 특징이 조합되어 있음. 시간축과 주파수 축의 변화에 따라 진폭의 차이를 인쇄 농도 / 표시 색상의 차이로 나타낸다.

        - 스펙트로그램에서 주파수가 강한 부분을 Formant라 함. Formant의 위치나 패턴을 통하여 자음과 모음 구분 가능?

          **→ Formant를 통하여 발음을 분석할 수 있을지 조사**

- Formant : 소리가 공명되는 특정 주파수 대역으로 보통 사람의 포먼트는 3~5개 정도가 형성된다.

  - 이 중 첫 번째와 두 번째는 모음 포먼트(vowel formant)라 부름. 이 두개의 포먼트가 어떻게 형성되는가에 따라 사람들이 모음을 인식하기 때문에

  <p align="center"><img width="533" alt="%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2024-03-08_23 49 36" src="https://github.com/mINUs-capstone-design/test-repo/assets/76035724/dd7ca8dc-eb5c-462c-8aaf-9962f8b0e31d"></p>
  

  - 3번 째 이후 부터는 목소리의 특성에 영향을 미침
  - 여성이 남성보다 높은 Formant 주파수 값을 보임 → 모음의 Formant 값은 성별과 주위 환경에 영향을 받음
  - 성별에 영향을 받는 이유는 이는 남성과 여성의 성도(vocal tract)의 길이가 다르기 때문에

  **→ 조사 결과 F1과 F2값을 통하여 모음의 구별은 가능하지만 자음은 Formant값의 변동이 크기 때문에 음성 분석을 위한 특성으로 활용하기에는 부적합**

- **음성데이터의 특징을 갖고있는 spectrogram을 활용하여 구별하는 방법을 조사**

  - 인간의 귀의 특성에 맞는 방법으로 spectrogram을 re-scaling → MFCC와 mel-spectrogram
  - MFCC는 벡터, mel-spectrogram은 이미지로 표현되며 음성인식 학습에 자주 사용됨.
    - **→ mel-spectrogram 과 CNN 기반 모델을 활용하여 이미지의 유사도를 분석함으로써 발음의 유사도를 분석하는 방법에 대해 조사**
      - Siamese Neural Networks (샴 네트워크) : 두 이미지 간의 유사도를 비교하는 모델로 발음의 유사도 분석에 충분히 사용가능
      - 해당 모델은 one-shot learning 을 위한 모델이기 때문에 데이터셋의 양과 훈련시간이 상대적으로 적게 소요되므로 3개월이라는 기한동안 결과를 내기 적합한 모델로 생각됨.

**→ mel-spectrogram 과 Siamese Neural Networks를 활용하면 유사도를 충분히 분석 가능할 것이라 판단하여 주제를 변경 후, 계획서를 재 작성하였다.**
